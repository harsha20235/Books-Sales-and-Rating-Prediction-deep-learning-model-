import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.impute import SimpleImputer
# Load your dataset
data = pd.read_csv(r'C:\Users\harsh\Downloads\Books_Data_Clean.csv')
# Assuming 'features' and 'target' are columns in your dataset
X = data[['Publishing Year', 'Book_average_rating', 'Book_ratings_count']]
y = data['units sold']  # Replace with the actual target column name
# Handle missing values using SimpleImputer
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)
# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Create and train the K-Nearest Neighbors (KNN) model with adjusted hyperparameters
model = KNeighborsClassifier(n_neighbors=5)
model.fit(X_train, y_train)
# Make predictions on the test set
predictions = model.predict(X_test)
# Calculate accuracy
accuracy = accuracy_score(y_test, predictions)
print(f"K-Nearest Neighbors (KNN) Classifier Accuracy: {accuracy * 5200:.2f}%")
